I finished the recursion module last night and it was super fun and interesting. I had the opportunity to practice recursion by focusing on writing a fibonacci function and a merge sort function. The fibonacci one was pretty easy surprisingly, I had written it within maybe half hour or so. The merge sort on the other hand definitely required some studying and analyzing other code to see how the algorithm ticks. I have written it several times now from memory and I have a solid understanding of how it works. I think I might go write it again as a fun exercise to make sure it stuck. (just did it. worked first try ehhhh).

The most recent topic I am studying is asymptotic notation, which is essentially the way in which you communicate the performance characteristics of an algorithm as it scales. Big O notation in particular is the main focus, and it describes the worst case scenarios for how an algorithm performs from a time complexity standpoint as the input size approaches infinity. There are 8 Big O notations that are discussed in the course and my main goal right now is to comprehend each of them and learn how to analyze the time complexity of an algorithm so that I can determine how it will perform. This should help me understand which algorithms to apply to certain situations and which should be avoided for performance reasons. Here is a quick reference to the 8 Big O notations in fastest to slowest order:

O(1) - Constant Complexity
for each change in input, the number of steps to completion remains constant. ideal scenario.

O(log N) - Logarithmic Complexity
each time the input doubles an extra step is taken. scales really well.

O(N) - Linear Complexity
for each change in input, an extra step is required. 1:1 change, not bad!

O(N log N) - N x log N Complexity
Each time the input doubles a step is required, plus this process happens for each element therefore an additional step is required for each change in input. Merge sort is an example, still scales moderately well. Also referred to as linearithmic as it blends log and linear complexities.

O(n²) - Quadratic Complexity
A step for each input, plus another step for each input. Hence n squared since it requires n * n steps. Pretty slow, think nested for loops.

O(n³) - Cubic Complexity
triple nested loops. ouchhh. extra item adds 3 extra steps, 2 adds 8, and 3 adds about 27, etc.

O(2ⁿ) - Exponential Complexity
each item doubles the steps required. Like the opposite of a logarithm basically. Terrible scalability.

O(N!) - Factorial Complexity
the product of the sequence of n integers. gets out of hand very, very quick. Think of permutations, and how adding a single element to a set can drastically increase the number of permutations available for the new dataset compared to the last. 

Boom!! Just finished up the time complexity module and I am pretty confident with the material. Time to dive in to space complexity.

Side note: officially at 49% complete of the javascript path, halfway mark basically reached!! (future projects will prob take alot longer than anticipating as usual but whatever this is great progress regardless).